import streamlit as st
import pandas as pd
import numpy as np
import requests
from sklearn.ensemble import RandomForestClassifier
import pickle
import os
import time
from datetime import datetime, timedelta

# ====== Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª ======
CACHE = "cache"
MODEL = "model"
TRADE_LOG = "trades.csv"
HISTORICAL = "historical_data"

for folder in [CACHE, MODEL, HISTORICAL]:
    if not os.path.exists(folder):
        os.makedirs(folder)

# ===============================
# Ø¬Ù„Ø¨ Ø£ÙØ¶Ù„ Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ù…Ù† CoinGecko Ø¨Ù…Ø§ ÙÙŠÙ‡Ø§ USDC
# ===============================
def get_top_symbols(limit=20):
    try:
        url = "https://api.coingecko.com/api/v3/coins/markets"
        params = {"vs_currency":"usd","order":"volume_desc","per_page":limit,"page":1}
        data = requests.get(url, params=params, timeout=10).json()
        symbols = [item["symbol"].upper() for item in data]
        return symbols
    except:
        return []

# ===============================
# Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª OHLCV Ù…Ù† CryptoCompare Ù…Ø¹ fallback Ù„CoinGecko
# ===============================
def fetch_ohlcv(symbol, interval="4h", limit=200):
    base = "https://min-api.cryptocompare.com/data/v2/"
    fsym = symbol
    tsym = "USDT"
    url = f"{base}{'histohour' if interval=='4h' else 'histoday'}?fsym={fsym}&tsym={tsym}&limit={limit}"
    try:
        data = requests.get(url).json()
        if data.get("Response") == "Success":
            df = pd.DataFrame(data["Data"]["Data"])
            hist_file = os.path.join(HISTORICAL, f"{symbol}_{interval}.csv")
            df.to_csv(hist_file, index=False)
            return df
    except:
        pass

    # Ù„Ùˆ ÙØ´Ù„ CryptoCompare (Ø®ØµÙˆØµØ§Ù‹ Daily)ØŒ Ù†Ø¬Ø±Ø¨ CoinGecko
    if interval == "daily":
        try:
            cg_url = f"https://api.coingecko.com/api/v3/coins/{symbol.lower()}/market_chart"
            params = {"vs_currency":"usd","days":limit,"interval":"daily"}
            data = requests.get(cg_url, params=params).json()
            if "prices" in data:
                df = pd.DataFrame(data["prices"], columns=["time","close"])
                df["time"] = pd.to_datetime(df["time"], unit="ms")
                df["high"] = df["close"]
                df["low"] = df["close"]
                df["open"] = df["close"]
                return df
        except:
            pass

    return pd.DataFrame()

# ===============================
# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª + ATR Ø­Ù‚ÙŠÙ‚ÙŠ
# ===============================
def add_indicators(df):
    df["close"] = df["close"].astype(float)
    df["high"] = df["high"].astype(float)
    df["low"] = df["low"].astype(float)
    df["EMA50"] = df["close"].ewm(span=50).mean()
    df["EMA200"] = df["close"].ewm(span=200).mean()
    df["prev_close"] = df["close"].shift(1)
    df["tr1"] = df["high"] - df["low"]
    df["tr2"] = abs(df["high"] - df["prev_close"])
    df["tr3"] = abs(df["low"] - df["prev_close"])
    df["TR"] = df[["tr1","tr2","tr3"]].max(axis=1)
    df["ATR"] = df["TR"].ewm(alpha=1/14, adjust=False).mean()
    df["return"] = df["close"].pct_change()
    return df.dropna()

# ===============================
# ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ AI
# ===============================
def train_ai(df, symbol):
    df["target"] = (df["close"].shift(-3) > df["close"]).astype(int)
    df = df.dropna()
    if len(df) < 100:
        return 0
    X = df[["EMA50","EMA200","ATR","return"]]
    y = df["target"]
    model_file = os.path.join(MODEL, f"{symbol}.pkl")
    if os.path.exists(model_file):
        model = pickle.load(open(model_file,"rb"))
    else:
        model = RandomForestClassifier(n_estimators=100, max_depth=5)
    try:
        model.fit(X,y)
        pickle.dump(model,open(model_file,"wb"))
        return model.predict_proba(X.iloc[-1:])[0][1]
    except:
        return 0

# ===============================
# Ø¥Ø¹Ø§Ø¯Ø© ØªØ¯Ø±ÙŠØ¨ AI Ø£Ø³Ø¨ÙˆØ¹ÙŠÙ‹Ø§
# ===============================
def weekly_retrain():
    if not os.path.exists(TRADE_LOG):
        return
    df = pd.read_csv(TRADE_LOG)
    if df.empty:
        return
    last_train_file = os.path.join(CACHE,"last_train.txt")
    if os.path.exists(last_train_file):
        with open(last_train_file,"r") as f:
            last_train_date = datetime.fromisoformat(f.read().strip())
        if datetime.now() - last_train_date < timedelta(days=7):
            return
    symbols = df["Ø§Ù„Ø¹Ù…Ù„Ø©"].unique()
    for sym in symbols:
        hist_file = os.path.join(HISTORICAL, f"{sym}_daily.csv")
        if os.path.exists(hist_file):
            df_hist = pd.read_csv(hist_file)
            df_hist = add_indicators(df_hist)
            train_ai(df_hist, sym)
    with open(last_train_file,"w") as f:
        f.write(datetime.now().isoformat())

# ===============================
# Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚ Ù„Ø¹Ù…Ù„Ø©
# ===============================
def market_condition(symbol):
    df = fetch_ohlcv(symbol,"daily",200)
    if df.empty:
        return "ØºÙŠØ± Ù…ØªØ§Ø­"
    df = add_indicators(df)
    last = df.iloc[-1]
    if last["close"] > last["EMA50"] > last["EMA200"]:
        return "ØµØ§Ø¹Ø¯"
    elif last["close"] < last["EMA50"] < last["EMA200"]:
        return "Ù‡Ø§Ø¨Ø·"
    else:
        return "Ø¹Ø±Ø¶ÙŠ"

# ===============================
# Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø¹Ø§Ù…
# ===============================
def overall_market(symbols):
    counts = {"ØµØ§Ø¹Ø¯":0,"Ù‡Ø§Ø¨Ø·":0,"Ø¹Ø±Ø¶ÙŠ":0}
    for s in symbols:
        state = market_condition(s)
        if state in counts:
            counts[state] += 1
    total = sum(counts.values())
    if total == 0:
        return "ØºÙŠØ± Ù…ØªØ§Ø­"
    best = max(counts, key=lambda k: counts[k])
    return f"{best} ({counts[best]}/{total})"

# ===============================
# ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙÙ‚Ø©
# ===============================
def log_trade(trade):
    if not os.path.exists(TRADE_LOG):
        df = pd.DataFrame(columns=list(trade.keys()))
        df = df.append(trade, ignore_index=True)
        df.to_csv(TRADE_LOG, index=False)
    else:
        df = pd.read_csv(TRADE_LOG)
        df = df.append(trade, ignore_index=True)
        df.to_csv(TRADE_LOG, index=False)

# ===============================
# ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù…Ø¹ ØªØ³Ø¬ÙŠÙ„ ÙƒÙ„ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª
# ===============================
def generate_signal(symbol):
    df4h = fetch_ohlcv(symbol,"4h",200)
    if df4h.empty:
        return {"Ø§Ù„Ø¹Ù…Ù„Ø©": symbol, "Ø¯Ø®ÙˆÙ„": np.nan, "ÙˆÙ‚Ù": np.nan, "Ù‡Ø¯Ù": np.nan,
                "Ø§Ø­ØªÙ…Ø§Ù„_Ø§Ù„ØµØ¹ÙˆØ¯": np.nan, "Ø­Ø§Ù„Ø©_Ø§Ù„Ø³ÙˆÙ‚": np.nan,
                "Ø­Ø§Ù„Ø© Ø§Ù„Ø¥Ø´Ø§Ø±Ø©": "Ù…Ø±ÙÙˆØ¶", "Ø³Ø¨Ø¨": "Ø¨ÙŠØ§Ù†Ø§Øª 4H ØºÙŠØ± Ù…ØªØ§Ø­Ø©"}

    df = add_indicators(df4h)
    last = df.iloc[-1]
    dfd = fetch_ohlcv(symbol,"daily",200)
    if dfd.empty:
        return {"Ø§Ù„Ø¹Ù…Ù„Ø©": symbol, "Ø¯Ø®ÙˆÙ„": np.nan, "ÙˆÙ‚Ù": np.nan, "Ù‡Ø¯Ù": np.nan,
                "Ø§Ø­ØªÙ…Ø§Ù„_Ø§Ù„ØµØ¹ÙˆØ¯": np.nan, "Ø­Ø§Ù„Ø©_Ø§Ù„Ø³ÙˆÙ‚": np.nan,
                "Ø­Ø§Ù„Ø© Ø§Ù„Ø¥Ø´Ø§Ø±Ø©": "Ù…Ø±ÙÙˆØ¶", "Ø³Ø¨Ø¨": "Ø¨ÙŠØ§Ù†Ø§Øª ÙŠÙˆÙ…ÙŠØ© ØºÙŠØ± Ù…ØªØ§Ø­Ø©"}

    dfd = add_indicators(dfd)
    if last["close"] < dfd["EMA50"].iloc[-1] and last["close"] < dfd["EMA200"].iloc[-1]:
        return {"Ø§Ù„Ø¹Ù…Ù„Ø©": symbol, "Ø¯Ø®ÙˆÙ„": np.nan, "ÙˆÙ‚Ù": np.nan, "Ù‡Ø¯Ù": np.nan,
                "Ø§Ø­ØªÙ…Ø§Ù„_Ø§Ù„ØµØ¹ÙˆØ¯": np.nan, "Ø­Ø§Ù„Ø©_Ø§Ù„Ø³ÙˆÙ‚": np.nan,
                "Ø­Ø§Ù„Ø© Ø§Ù„Ø¥Ø´Ø§Ø±Ø©": "Ù…Ø±ÙÙˆØ¶", "Ø³Ø¨Ø¨": "Ø§Ù„Ø³Ø¹Ø± ØªØ­Øª EMA50 Ùˆ EMA200 ÙŠÙˆÙ…ÙŠ"}

    prob = train_ai(df,symbol)
    entry = last["close"]
    atr = last["ATR"]
    stop = entry - atr*1.2
    target = entry + atr*1.8

    if prob < 0.55:
        trade_status = "Ù…Ø±ÙÙˆØ¶"
        reason = f"Ù‚ÙˆØ© AI Ø¶Ø¹ÙŠÙØ© ({round(prob*100,2)}%)"
    else:
        trade_status = "Ù…Ù‚Ø¨ÙˆÙ„"
        reason = ""

    trade = {"Ø§Ù„Ø¹Ù…Ù„Ø©":symbol, "ØªØ§Ø±ÙŠØ®":datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
             "Ø¯Ø®ÙˆÙ„":round(entry,4) if trade_status=="Ù…Ù‚Ø¨ÙˆÙ„" else np.nan,
             "ÙˆÙ‚Ù":round(stop,4) if trade_status=="Ù…Ù‚Ø¨ÙˆÙ„" else np.nan,
             "Ù‡Ø¯Ù":round(target,4) if trade_status=="Ù…Ù‚Ø¨ÙˆÙ„" else np.nan,
             "Ø§Ø­ØªÙ…Ø§Ù„_Ø§Ù„ØµØ¹ÙˆØ¯":round(prob*100,2),
             "Ø­Ø§Ù„Ø©_Ø§Ù„Ø³ÙˆÙ‚":market_condition(symbol),
             "Ø­Ø§Ù„Ø© Ø§Ù„Ø¥Ø´Ø§Ø±Ø©": trade_status,
             "Ø³Ø¨Ø¨": reason}
    log_trade(trade)
    return trade

# ===============================
# Ø³ÙƒØ§Ù† Ø§Ù„Ø³ÙˆÙ‚ Ù…Ø¹ ØªØ±Ù‚ÙŠÙ… Ù…Ù† 1
# ===============================
def scan_market():
    weekly_retrain()
    symbols = get_top_symbols(20)
    results = []
    for s in symbols:
        try:
            results.append(generate_signal(s))
            time.sleep(0.3)
        except:
            results.append({"Ø§Ù„Ø¹Ù…Ù„Ø©": s, "Ø¯Ø®ÙˆÙ„": np.nan, "ÙˆÙ‚Ù": np.nan, "Ù‡Ø¯Ù": np.nan,
                            "Ø§Ø­ØªÙ…Ø§Ù„_Ø§Ù„ØµØ¹ÙˆØ¯": np.nan, "Ø­Ø§Ù„Ø©_Ø§Ù„Ø³ÙˆÙ‚": np.nan,
                            "Ø­Ø§Ù„Ø© Ø§Ù„Ø¥Ø´Ø§Ø±Ø©": "Ù…Ø±ÙÙˆØ¶", "Ø³Ø¨Ø¨": "Ø®Ø·Ø£ Ø¹Ø§Ù…"})
    df = pd.DataFrame(results)
    df.index = np.arange(1, len(df)+1)
    return df

# ===============================
# ÙˆØ§Ø¬Ù‡Ø© Streamlit Ø¨Ø¯ÙˆÙ† Ø¬Ø¯ÙˆÙ„ ÙØ§Ø¶ÙŠ Ø¹Ù†Ø¯ Ø§Ù„ÙØªØ­
# ===============================
st.markdown('<h4 style="font-size:16px;">AI Spot Scanner</h4>', unsafe_allow_html=True)
symbols = get_top_symbols(20)
st.markdown(f"### ğŸ§­ Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø¹Ø§Ù…: {overall_market(symbols)}")

def highlight_rows(row):
    color = 'background-color: #d4f8d4' if row.get('Ø­Ø§Ù„Ø© Ø§Ù„Ø¥Ø´Ø§Ø±Ø©')=='Ù…Ù‚Ø¨ÙˆÙ„' else 'background-color: #f8d4d4'
    return [color]*len(row)

# Ø²Ø±Ø§Ø± Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ÙØ­Øµ ÙŠØ¯ÙˆÙŠÙ‹Ø§
if st.button("ğŸ” ÙØ­Øµ Ø§Ù„Ø³ÙˆÙ‚ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰"):
    df = scan_market()
    st.dataframe(df.style.apply(highlight_rows, axis=1))
    if (df["Ø­Ø§Ù„Ø© Ø§Ù„Ø¥Ø´Ø§Ø±Ø©"]=="Ù…Ù‚Ø¨ÙˆÙ„").any():
        st.success("ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙÙ‚Ø§Øª ÙˆØªØ­Ø³ÙŠÙ† ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª!")
    else:
        st.info("Ù„Ù… ÙŠØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø£ÙŠ ØµÙÙ‚Ø© Ø¬Ø¯ÙŠØ¯Ø©ØŒ Ù„ÙƒÙ† ØªÙ… ÙØ­Øµ Ø§Ù„Ø³ÙˆÙ‚!")
